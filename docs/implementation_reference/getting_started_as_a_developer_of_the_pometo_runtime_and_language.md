# Getting Started As A Developer Of The Pometo Runtime And Language

## Basic Dev Cycle

The core development cycle is:

* write a documentation page description the operation that you wish to add and the results it should show
	* documentation pages are turned into tests - the title of test is the filename - so your docs pages should not have the same name as anyother page
* generate the new test suite with the command `rebar3 pometo_docs_to_tests`
    * the `pometo_docs_to_tests` `rebar3` plugin is fairly stable but does occassionally change
    * to fetch and run a new version delete the directory `_build/default/plugins/pometo_docs_to_test` and your next call of any `rebar3` command will fetch and install the latest version
* run the tests with `rebar3 eunit`
    * you can run a single test suite with a command like `rebar3 eunit --module=complex_numbers_tests`

Code failures in tests are fairly hard to debug because the interpreter and compiler both capture and sanitize runtime errors.

The easiest way to proceed is to copy the input string of the test into the `runner` module and then invoke it with the `run.sh` bash command in `%ROOT`

This runs the same code as a plain Erlang function and you get the full, raw crash report.

There is a pain here - to see debugging output when running test suites you need to use the `?debugFmt` macro (it has the same arguments as `io:format/2` (there is no equivalent to `io:format/1`). It is defined in the eunit include file and added to source code with `-include_lib("eunit/include/eunit.hrl").`

These two output methods don't work with each other `io:format`s don't show when running tests and `?debugFmt`s don't show when running code :-(

This can tend to lead to dirty code with extra `io:format`s and `?debugFmt`s littering the code. Please check your diffs before submitting a PR.

## How To Write Docs Pages As Tests

Docs pages have a simple format.

A markdown code section like so will become the input source:

```pometo
1 + 2
```

The next markdown code section MUST be marked up as:

```pometo_results
3
```

The `pometo_docs_to_test` `rebar3` plugin will turn this page into a test file `get_started_as_a_developer_tests.erl` in `test/generated_tests` and it will contain a single test `how_to_write_docs_pages_as_tests_1_test_/0`.

It names each test from the second level heading that preceeded it in this case from `##How To Write Docs Pages As Tests` with an incrementing sequence number.

The sequence deliberately increases over the whole document page - this is to ensure there isn't a test name clash if the same sub-heading is used.

You can then run this page with `rebar3 eunit --module=get_started_as_a_developer_tests`.

This is what the generated test looks like. The `pometo` section has been mapped to the code variable. The `pometo_results` section has become the expectation.

Note that two tests have been generated - an interpreted one and a compiled on. (The interpreted code path is run in [Rappel](https://github.com/gordonguthrie/rappel/) - the `pometo` RAPL.

`eunit` macros don't play that well with unicode and failures tend to be hard to decipher. To that end a commented out `debugFmt` statement is generated. Uncomment that, re run the tests and voila readable failure reports.

```erlang
%%% DO NOT EDIT this test suite is generated by the pometo_docs_to_test rebar3 plugin

-module(getting_started_as_a_developer_of_the_pometo_runtime_and_language_tests).

-include_lib("eunit/include/eunit.hrl").

-compile([export_all]).

how_to_write_docs_pages_as_tests_1_interpreter_test_() ->
    Code     = ["1 + 2"],
    Expected = "3",
    Got = pometo_test_helper:run_interpreter_test(Code),
    % ?debugFmt(" in how_to_write_docs_pages_as_tests_1_interpreter~nCode:~n~ts~nExp:~n~ts~nGot:~n~ts~n", [Code, string:trim(Expected), string:trim(Got)]),
    ?_assertEqual(string:trim(Expected), string:trim(Got)).

how_to_write_docs_pages_as_tests_1_compiler_test_() ->
    Code     = ["1 + 2"],
    Expected = "3",
    Got = pometo_test_helper:run_compiler_test("how_to_write_docs_pages_as_tests_1_compiler", Code),
    % ?debugFmt(" in how_to_write_docs_pages_as_tests_1_compiler~nCode:~n~ts~nExp:~n~ts~nGot:~n~ts~n", [Code, string:trim(Expected), string:trim(Got)]),
    ?_assertEqual(string:trim(Expected), string:trim(Got)).
```

If you screw up your code sections you tests can become wierd and very badly failing for that test module. If the results seem super wacko look at the test source and check it is same. This can be as simple as a missing backtick or mis-ordered sections.

A cheap and quick way to see if the sets of code and results are correctly done hokey-cokey fashion is to run
```
grep -Rh "\`\`\`p" docs/*
```

and inspect the output.

Try writing doc tests.

## Adding Documentation

The goal is to build documentation as we go along so any features added to the system need to have associated documentation (and hence tests-generated-from-the-documentation) written as we go along.

Documentation is stored in a structured set of directories under `docs/`. To add a page to the table of contents please edit `docs/_data/contents.yml`.

Please manually check that the documentation builds before you commit your change. (There is one known and unavoidable problem: the string `{{` is interpreted as a template command and you need to write your `apl` a bit more spaced out - `{ {`.

To build the docs locally start the docker file and `cd /pometo/docs` and run the bash script `./run_jekyll.sh`. This will build the docs and serve them on `0.0.0.0:4000`. They can be accessed on your host machine at `http://localhost:4000`.

## What Happens If A Million Tests Fail?

Don't panic. Tests suites shadow each other. That is to say if a particulary test fails we can predict which other test suites will also fail. Understanding the shadow order helps you decide which of your million failing tests to fix.

The core lexer/parser tests are not generated from docs - run them first.

To do that simply delete all the generated tests (they are not stored in `git` the documentation is the primary source of them) `rm test/generated_tests/*`.

Run `rebar3 eunit` and if there are any failing tests in there fix them. If there is a primitive lexer or parser bug you would expect all tests that use the failing feature to fail also - and therefore this test failure will ***cast its shadow*** onto the feature test suites.

Once the primitive tests are all passing make sure the basic runtime test suite passes. This is described in the documentation page `basics.md`.

To do this first generate the documentation with `rebar3 pometo_docs_to_tests` and then run `rebar3 eunit --module=basics_tests`

This test suite just tests the execution paths of `pometo_runtime` and again a failure here will shadow onto lots of feature tests. Once this test paths you are left with your final feature bugs to fix.

## Rebar Has Crashed!

Ah, are you sure you types `rebar3 ....` and not `rebar ...` becuz `rebar` is also installed as a tool and it doesn't play with `pometo` because of our custom `rebar3` plugin.

## Working On The Runtime

If you are working on the runtime please to add the simplest smoke tests to the documentation page `basics.md`